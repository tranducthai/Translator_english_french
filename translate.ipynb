{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MejWbVKII7u",
        "outputId": "6ba1275b-93a7-4566-ad8c-c8dd2e9ff44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import scipy\n",
        "import sklearn\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "import pdb\n",
        "import pickle"
      ],
      "metadata": {
        "id": "Td9Syx9AJfvv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "  tweet=re.sub(r'\\$\\w*','',tweet)\n",
        "  tweet=re.sub(r'https?:\\/\\/.*[\\r\\n]*','',tweet)\n",
        "  tweet=re.sub(r'#','',tweet)\n",
        "  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "  stemmer=PorterStemmer()\n",
        "  clean_word=[]\n",
        "  tokenizer=TweetTokenizer(preserve_case=False,reduce_len=True,strip_handles=True)\n",
        "  words=tokenizer.tokenize(tweet)\\\n",
        "\n",
        "  for word in words:\n",
        "    if word not in stopwords.words('english') and word not in string.punctuation:\n",
        "      stem_word=stemmer.stem(word)\n",
        "      clean_word.append(stem_word)\n",
        "  return clean_word"
      ],
      "metadata": {
        "id": "AZTXVpA1KAlz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a='What the weather like today I think it is sunny'\n",
        "print(process_tweet(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4JpmVlzZ0iD",
        "outputId": "c6ef7da1-ab09-4507-8f75-7d95291168e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['weather', 'like', 'today', 'think', 'sunni']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_dict(path):\n",
        "  data=pd.read_csv(path,delimiter=' ')\n",
        "  dict={}\n",
        "  for i in range((len(data))):\n",
        "    eng=data.loc[i][0]\n",
        "    france=data.loc[i][1]\n",
        "    dict[eng]=france\n",
        "\n",
        "  return dict\n"
      ],
      "metadata": {
        "id": "5IbJh9nRalwV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpYXN4SKN-9Y",
        "outputId": "e31724e9-4470-433b-c986-221a8e79a751"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path='/content/drive/My Drive/en-fr.train.txt'\n",
        "en_fra_train=get_dict(folder_path)\n",
        "en_fra_test=get_dict('/content/drive/My Drive/en-fr.test.txt')\n",
        "en_fra_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hu-1THxOR8i",
        "outputId": "834ea1a3-d679-4fd4-d1c9-44043f0a290a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'torpedo': 'torpilles',\n",
              " 'giovanni': 'giovanni',\n",
              " 'chat': 'chat',\n",
              " 'catholics': 'catholiques',\n",
              " 'herald': 'herald',\n",
              " 'chuck': 'chuck',\n",
              " 'pit': 'fosse',\n",
              " 'supplied': 'fournie',\n",
              " 'optional': 'facultatives',\n",
              " 'garrison': 'garnison',\n",
              " 'sprint': 'sprint',\n",
              " 'exile': 'exilés',\n",
              " 'surprised': 'étonnée',\n",
              " 'achievements': 'réalisations',\n",
              " 'biblical': 'bibliques',\n",
              " 'rebels': 'rebelles',\n",
              " 'denis': 'denis',\n",
              " 'geographical': 'géographique',\n",
              " 'sit': 'sit',\n",
              " 'alpine': 'alpine',\n",
              " 'bills': 'factures',\n",
              " 'glacier': 'glaciers',\n",
              " 'binding': 'reliure',\n",
              " 'indicating': 'indiquant',\n",
              " 'estonia': 'estonie',\n",
              " 'eating': 'manger',\n",
              " 'saving': 'économiser',\n",
              " 'chi': 'chi',\n",
              " 'developer': 'développeurs',\n",
              " 'indie': 'indie',\n",
              " 'difficulties': 'difficultés',\n",
              " 'doctrine': 'doctrine',\n",
              " 'worn': 'porté',\n",
              " 'fork': 'fourches',\n",
              " 'simpson': 'simpson',\n",
              ...
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_of_two_vector(v1,v2):\n",
        "  a=np.dot(v1,v2)\n",
        "  n1=np.linalg.norm(v1)\n",
        "  n2=np.linalg.norm(v2)\n",
        "  return a/(n1*n2)\n"
      ],
      "metadata": {
        "id": "AYugeOHPURjj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "url = 'https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.fr.vec'\n",
        "response = requests.get(url)\n",
        "open('wiki.multi.fr.vec', 'wb').write(response.content)\n",
        "fr_embeddings = KeyedVectors.load_word2vec_format('wiki.multi.fr.vec')\n",
        "word_vector = fr_embeddings['exemple']\n",
        "print(word_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPrtK1__V1LK",
        "outputId": "4cc42616-1eee-4aeb-ec81-0b291896c15f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.0133558   0.0561406  -0.0694209   0.0311983  -0.0872903   0.126163\n",
            "  0.0362641  -0.163533    0.0380523  -0.00480411 -0.0251462   0.00875403\n",
            " -0.0115927  -0.0331937   0.0552742  -0.096852    0.0220379   0.128896\n",
            "  0.0598265   0.0446406   0.0210739   0.0317773  -0.0148385  -0.0412769\n",
            "  0.0030318  -0.0770004  -0.038513    0.0455751  -0.0695123  -0.00796328\n",
            " -0.029034    0.0639054  -0.00533526  0.109268   -0.0359792   0.00555054\n",
            "  0.022049    0.0775119  -0.00584307  0.0119937   0.0215752   0.0278726\n",
            " -0.0536905   0.00322845 -0.00312756  0.0212549  -0.00455244 -0.0440737\n",
            "  0.0995931  -0.0326344  -0.00153035 -0.0843178  -0.0254944  -0.0667438\n",
            " -0.0788062   0.0191735   0.0291632  -0.0503336  -0.0319285   0.0624556\n",
            " -0.0595765  -0.0560902   0.0371551  -0.0656051  -0.0254122   0.0919526\n",
            "  0.0405275  -0.0924167   0.056076   -0.0232076  -0.047295    0.0252905\n",
            "  0.0444518  -0.0943727  -0.0973599   0.0577101   0.121024   -0.0208405\n",
            " -0.0381557   0.0163463   0.0808563   0.0560757  -0.102797   -0.0545675\n",
            "  0.0527368   0.0363802   0.0353754   0.0438106  -0.0156768  -0.019177\n",
            "  0.120941   -0.00344512  0.125547   -0.153083    0.0440876  -0.0123152\n",
            "  0.0839643   0.0774253  -0.0501733  -0.016517   -0.0171989  -0.0650993\n",
            "  0.0304449  -0.0657151  -0.0324649   0.0229146   0.00476649  0.0663574\n",
            "  0.0430456   0.0913181   0.00466381  0.00155344 -0.0924206   0.0137529\n",
            "  0.0265865   0.0687676  -0.00352471  0.0240951   0.00286801  0.0628522\n",
            "  0.0823236   0.0621679  -0.0803754   0.149304   -0.00564278 -0.0716502\n",
            "  0.0119765  -0.0123222   0.00699296  0.112744    0.0642991   0.0545198\n",
            " -0.00184796  0.0524718   0.0558364   0.0338136  -0.0116617   0.00446409\n",
            "  0.0564059   0.058129    0.00610078  0.0161327   0.0974386   0.0354506\n",
            " -0.0290721   0.0779223  -0.0522912  -0.0795312  -0.0986203  -0.0132567\n",
            "  0.0209576  -0.121666   -0.00345285 -0.11319     0.00483152 -0.0389006\n",
            "  0.0781456  -0.04544     0.041119    0.00703151 -0.0252818   0.0300373\n",
            " -0.097686   -0.0759262   0.0168523  -0.00668055  0.0371575  -0.0384651\n",
            "  0.061561    0.0113967  -0.0621795   0.0221526  -0.0232187  -0.0152078\n",
            " -0.042372    0.0304755  -0.00058084  0.0805255   0.0545397  -0.0190584\n",
            "  0.0792582   0.0029046   0.0626017   0.0691927   0.0210336   0.0586272\n",
            " -0.0440277  -0.0465004   0.019752   -0.0268877   0.0429094  -0.0911103\n",
            " -0.00281409 -0.0266954  -0.0114973  -0.0684068   0.0198621   0.0890199\n",
            " -0.134863   -0.0305137   0.0714594  -0.0174175   0.0426475   0.0432636\n",
            "  0.0513172  -0.0727861  -0.102371    0.00446702  0.00870757  0.0212783\n",
            "  0.144378    0.00624511  0.0856862   0.0455556   0.101228    0.0196452\n",
            "  0.0479495  -0.0536713  -0.121112    0.0434358  -0.00035195 -0.0683625\n",
            " -0.0698439  -0.0113668  -0.0140444   0.0417835  -0.09509    -0.0855703\n",
            " -0.00567464 -0.0358154  -0.0529393   0.0493911  -0.039891   -0.0618215\n",
            " -0.0424574   0.0800796   0.0442032   0.00192788  0.0457474   0.0467245\n",
            " -0.0792062  -0.0343039   0.00704985 -0.0339736  -0.0207451   0.108139\n",
            "  0.095021    0.0452066  -0.0144158   0.0121867   0.0190242  -0.0478475\n",
            " -0.0454784   0.0288868  -0.0414201  -0.024097    0.0503903  -0.0017657\n",
            " -0.0361284  -0.0529264   0.0296352  -0.0197037  -0.0493869   0.0256912\n",
            " -0.131603   -0.0363103  -0.104518    0.0463835  -0.0585176   0.033499\n",
            " -0.0919761  -0.0458632   0.0450371  -0.0468578  -0.00083238  0.00731992\n",
            "  0.00103627 -0.00805574  0.0116149   0.00521298  0.0817934   0.0178197\n",
            " -0.0208177   0.0848187   0.0421869  -0.0613403   0.07581     0.09204\n",
            " -0.104155    0.0766356  -0.0195039  -0.0282539   0.030879   -0.00424222\n",
            " -0.0556627  -0.0972723  -0.0524801   0.0265557   0.0783776   0.020809  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec'\n",
        "response = requests.get(url)\n",
        "open('wiki.multi.en.vec', 'wb').write(response.content)\n",
        "en_embeddings = KeyedVectors.load_word2vec_format('wiki.multi.en.vec')\n",
        "# Check if the model is loaded by getting the vector for a word\n",
        "word_vector = en_embeddings['day']  # Replace 'exemple' with any word present in the model\n",
        "print(word_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZK2vAJrvkUi",
        "outputId": "21298bfc-228f-4fe7-b4fd-8062978b4e2b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 4.39049e-02 -3.01736e-02  3.48466e-02  3.44264e-03 -7.86043e-02\n",
            " -2.44871e-02  5.52975e-02  2.19620e-02  4.91441e-02  1.51650e-02\n",
            "  5.50675e-02 -3.12423e-04  1.45620e-02  1.62794e-02  3.89202e-03\n",
            " -8.62914e-03  1.14209e-02 -6.82546e-02  4.70859e-02  1.32767e-01\n",
            " -9.08497e-03  1.08739e-01 -1.76859e-02 -4.03343e-02 -5.29509e-03\n",
            "  8.55981e-03  1.72144e-02 -1.53632e-05 -3.80613e-02 -2.35914e-02\n",
            "  8.25858e-03 -2.56822e-02 -1.10371e-01  3.98742e-02 -1.86801e-02\n",
            " -1.06745e-01  5.56625e-02 -5.87208e-02 -9.21319e-03 -1.18988e-02\n",
            "  5.17454e-02 -3.19049e-02 -8.26871e-03  5.92975e-02  4.90153e-02\n",
            " -2.40288e-02  7.42300e-02  5.77914e-02  2.25785e-02 -6.84110e-02\n",
            "  3.32024e-02  1.54196e-03  4.65521e-02 -7.40797e-02 -3.26564e-03\n",
            "  3.09264e-02 -2.78282e-02  5.59294e-02 -4.27208e-02  7.16196e-02\n",
            "  4.41165e-02 -4.44540e-02  6.77883e-04 -7.73466e-02 -4.23405e-02\n",
            " -4.74018e-02 -8.71441e-02  4.50276e-02 -3.85337e-02  8.77484e-02\n",
            " -4.16840e-02  6.92208e-02 -4.40951e-02 -5.59877e-02 -6.53343e-02\n",
            " -4.86319e-02  1.86662e-01 -4.34264e-02  9.19233e-03 -2.45015e-02\n",
            "  1.18721e-01  4.80736e-02  5.57300e-02  4.53343e-02 -4.02791e-02\n",
            "  1.70816e-01 -2.23966e-02  7.04846e-02  2.64445e-02  2.25847e-02\n",
            " -3.54509e-02  4.08650e-02 -6.17975e-03 -4.45399e-02  2.20580e-02\n",
            "  5.02852e-02 -8.88527e-02  4.10061e-03 -1.44058e-02 -1.19540e-01\n",
            " -3.40030e-02  8.63159e-03 -6.51349e-03  3.24938e-02 -5.65306e-02\n",
            "  4.11227e-02 -4.75030e-02  1.15169e-01  1.27675e-02  2.29046e-02\n",
            "  3.40889e-02 -3.28374e-03 -8.62730e-02 -1.03638e-01  2.49359e-02\n",
            " -5.72822e-02  1.66972e-02 -3.36595e-03 -3.54662e-02  3.09141e-02\n",
            "  1.21770e-01  7.87515e-03 -3.79110e-02  6.74018e-02  1.21251e-01\n",
            " -6.83067e-02  4.38834e-02  3.82883e-02  8.44662e-03  4.71441e-02\n",
            " -2.37978e-02  5.20245e-02 -4.41810e-02 -5.04540e-02  6.97607e-02\n",
            " -8.65644e-02  1.00396e-02  5.39448e-02  6.98834e-03  1.17896e-01\n",
            "  4.11994e-02 -6.08742e-02 -3.60460e-02  6.55245e-02  2.71236e-02\n",
            "  7.90337e-02  7.27914e-02 -1.50709e-01 -8.73742e-02 -8.09141e-02\n",
            "  6.33343e-02 -5.14478e-02 -1.16773e-01  5.49601e-03 -3.17699e-02\n",
            " -2.64650e-02  2.34245e-02 -3.01684e-02  1.05469e-01 -4.63895e-02\n",
            "  4.99601e-02 -1.66482e-02 -5.65061e-02  7.01717e-02  1.07896e-01\n",
            "  7.72147e-02 -2.26374e-02  4.01012e-02  6.96012e-03  1.25865e-02\n",
            " -6.62116e-03  3.17577e-03 -8.13865e-02 -6.78865e-02  8.58681e-02\n",
            "  5.76288e-02 -9.32975e-02  4.58466e-02  7.03466e-02 -1.07874e-02\n",
            "  1.24297e-02 -8.79171e-02  1.47276e-02  3.70276e-02 -3.93650e-02\n",
            "  1.90273e-02 -2.16310e-02 -4.68251e-02  1.00626e-01 -5.98650e-02\n",
            "  7.71104e-02 -1.25074e-02  4.83988e-02  2.93816e-02 -9.78374e-02\n",
            " -5.34662e-03 -1.85457e-03 -5.01994e-03 -1.29101e-01 -1.34957e-02\n",
            " -6.81533e-02 -9.10674e-03 -2.71307e-04  2.20049e-02  1.09405e-01\n",
            "  5.91288e-02  6.79263e-02  6.56441e-02  6.99325e-02  1.00521e-04\n",
            "  2.04948e-01 -4.96626e-02  1.39546e-02 -9.49386e-02 -6.35245e-03\n",
            "  3.19202e-02 -8.28220e-03 -1.20264e-01  3.99785e-02  1.01874e-01\n",
            "  6.24693e-02 -1.19681e-02 -3.11564e-02  1.01316e-01 -3.88619e-03\n",
            "  3.46227e-02 -9.08865e-03  6.98006e-03 -3.21350e-02 -7.05767e-03\n",
            "  5.57178e-02  6.02055e-02  5.06963e-02  6.01748e-02  3.48742e-02\n",
            " -2.78472e-02 -4.23865e-02 -1.53218e-02  1.00212e-01 -6.29969e-02\n",
            "  7.16932e-02 -9.10828e-02  7.62883e-02  4.24356e-03 -1.17058e-02\n",
            "  6.00490e-02  4.42208e-02  1.05172e-02  7.14171e-02 -1.61417e-02\n",
            "  3.19816e-02  8.49723e-02 -7.03895e-02 -8.97392e-03 -1.19061e-02\n",
            " -6.95460e-02 -1.34021e-01 -6.34018e-02 -3.91442e-02  4.27116e-02\n",
            "  9.70521e-02  4.54448e-02 -2.19945e-02 -1.02712e-01 -3.40644e-02\n",
            " -5.15092e-02 -4.33926e-02 -2.72727e-02 -2.64331e-02 -8.38803e-02\n",
            " -4.35889e-02 -6.61717e-04  2.40914e-02 -6.41963e-03 -4.72576e-02\n",
            " -7.48220e-02 -2.06666e-02 -1.62147e-02  4.11257e-02  1.49549e-02\n",
            " -4.28497e-02 -4.11411e-03  5.08282e-02 -1.76043e-02 -4.58865e-03\n",
            "  2.92494e-02  2.79708e-02 -2.33920e-02 -3.28497e-02  8.86993e-03\n",
            " -9.68343e-03 -4.49080e-02 -8.95521e-04 -4.05092e-03 -5.12300e-02\n",
            "  7.93589e-02 -6.71595e-02 -3.42362e-02  5.72730e-02  7.21043e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_set = set(en_embeddings.key_to_index.keys())\n",
        "french_set = set(fr_embeddings.key_to_index.keys())\n",
        "en_embeddings_subset = {}\n",
        "fr_embeddings_subset = {}\n",
        "french_words = set(en_fra_train.values())\n",
        "for en_word in en_fra_train.keys():\n",
        "    fr_word = en_fra_train[en_word]\n",
        "    if fr_word in french_set and en_word in english_set:\n",
        "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
        "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
        "\n",
        "\n",
        "for en_word in en_fra_test.keys():\n",
        "    fr_word = en_fra_test[en_word]\n",
        "    if fr_word in french_set and en_word in english_set:\n",
        "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
        "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
        "\n",
        "\n",
        "pickle.dump( en_embeddings_subset, open( \"en_embeddings.p\", \"wb\" ) )\n",
        "pickle.dump( fr_embeddings_subset, open( \"fr_embeddings.p\", \"wb\" ) )"
      ],
      "metadata": {
        "id": "MTzk2S7-xS-c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_matrix(en_fr,en_vec,fr_vec):\n",
        "  x_list=list()\n",
        "  y_list=list()\n",
        "  english_set=en_vec.keys()\n",
        "  france_set=fr_vec.keys()\n",
        "  france_words=set(en_fr.values())\n",
        "  for en_word, fr_word in en_fr.items():\n",
        "        if fr_word in fr_vec and en_word in en_vec:\n",
        "            en_embedding = en_vec[en_word]\n",
        "            fr_embedding = fr_vec[fr_word]\n",
        "            x_list.append(en_embedding)\n",
        "            y_list.append(fr_embedding)\n",
        "\n",
        "  X = np.vstack(x_list)\n",
        "  Y = np.vstack(y_list)\n",
        "  return X, Y\n"
      ],
      "metadata": {
        "id": "LwsTcIcB5Abk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_embeddings_subset = pickle.load(open(\"en_embeddings.p\", \"rb\"))\n",
        "fr_embeddings_subset = pickle.load(open(\"fr_embeddings.p\", \"rb\"))\n",
        "x_train,y_train=get_matrix(en_fra_train,en_embeddings_subset,fr_embeddings_subset)"
      ],
      "metadata": {
        "id": "5IWpQVsl-H33"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.array(x_train)\n",
        "y_train=np.array(y_train)\n",
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5d1r2yV_S_6",
        "outputId": "5dad2054-1c9d-4d88-aff8-9ff97205a83b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 300), (5000, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.linalg import orthogonal_procrustes\n",
        "R,_=orthogonal_procrustes(x_train,y_train)\n",
        "R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSNQo31iAtVk",
        "outputId": "cce914f6-ef65-43b6-c2bb-933e82dbb681"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.80879164, -0.00400219, -0.02734789, ..., -0.02883246,\n",
              "        -0.01982565,  0.02612439],\n",
              "       [ 0.03065553,  0.8275611 ,  0.09199339, ...,  0.02687369,\n",
              "         0.00631984,  0.04344907],\n",
              "       [ 0.08258763, -0.02589141,  0.8044921 , ...,  0.04021224,\n",
              "         0.00922842, -0.06730425],\n",
              "       ...,\n",
              "       [-0.03478248,  0.03102311, -0.03719375, ...,  0.83638465,\n",
              "        -0.0234507 ,  0.04584297],\n",
              "       [ 0.03411265,  0.07941602, -0.05997404, ...,  0.04701069,\n",
              "         0.84207547, -0.03437557],\n",
              "       [-0.00637255,  0.00189635,  0.03001869, ..., -0.03473854,\n",
              "        -0.04046868,  0.8287463 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbor(v, candidates, k=1):\n",
        "    similarity_l = []\n",
        "    for row in candidates:\n",
        "        cos_similarity = cos_of_two_vector(v,row)\n",
        "        similarity_l.append(cos_similarity)\n",
        "    sorted_ids = np.argsort(similarity_l)\n",
        "    k_idx = sorted_ids[-k:]\n",
        "    return k_idx\n",
        "def test_vocabulary(X, Y, R):\n",
        "    pred = np.dot(X,R)\n",
        "    num_correct = 0\n",
        "    for i in range(len(pred)):\n",
        "        pred_idx = nearest_neighbor(pred[i],Y)\n",
        "        if pred_idx == i:\n",
        "            num_correct += 1\n",
        "    accuracy = num_correct / len(pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "W1dTj7wWA_rA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test,y_test=get_matrix(en_fra_test,en_embeddings_subset,fr_embeddings_subset)\n",
        "acc = test_vocabulary(x_test, y_test, R)\n",
        "print(f\"accuracy on test set is {acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2DtRPsHBf8Q",
        "outputId": "b274cfb0-f70c-45dc-c21d-b1f3168c8aee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on test set is 0.807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translate"
      ],
      "metadata": {
        "id": "2G1k1TOdS9gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_word(word, en_embeddings_subset,R):\n",
        "    if word not in en_embeddings_subset:\n",
        "        return None\n",
        "    en_vector = en_embeddings_subset[word]\n",
        "    fr_vector = np.dot(R, en_vector)\n",
        "    return fr_vector"
      ],
      "metadata": {
        "id": "JEnez5hxHs4j"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "def find_closest_word(vector, embeddings_subset):\n",
        "    closest_word = None\n",
        "    min_distance = float('inf')\n",
        "    for word, embedding in embeddings_subset.items():\n",
        "        distance = cosine(vector, embedding)\n",
        "        if distance < min_distance:\n",
        "            min_distance = distance\n",
        "            closest_word = word\n",
        "    return closest_word"
      ],
      "metadata": {
        "id": "xs81VgChUYPQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_and_find(word, en_embeddings_subset, fr_embeddings_subset, R):\n",
        "    fr_vector = translate_word(word, en_embeddings_subset, R)\n",
        "    if fr_vector is None:\n",
        "        return None\n",
        "\n",
        "    closest_word = find_closest_word(fr_vector, fr_embeddings_subset)\n",
        "    return closest_word"
      ],
      "metadata": {
        "id": "iEeSaeLaUkUX"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set=['free','house','music','know','field']\n",
        "translated=[]\n",
        "for word in set:\n",
        " translated_word = translate_and_find(word, en_embeddings_subset, fr_embeddings_subset, R)\n",
        " translated.append(translated_word)\n",
        "translated\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcoIa5IxUvzu",
        "outputId": "90ee3584-95f2-411f-ceee-1c9928a17145"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['libre', 'maison', 'musique', 'crois', 'champs']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "efAUyFF1S80F"
      }
    }
  ]
}
